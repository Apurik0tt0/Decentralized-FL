import copy
from typing import Sequence
import numpy as np
import torch
from fluke.server import Server
from fluke.client import Client
from fluke.comm import Message
from fluke.utils.model import aggregate_models
from rich.table import Table
from rich.console import Console
from fluke import FlukeENV


class P2PServer(Server):
    def __init__(self, model, test_set, clients, **kwargs):
        """
        adjacency_matrix: dict[int, list[int]] 
                          Ex: {0: [1, 2], 1: [0, 3], ...}
        """
        super().__init__(model, test_set, clients, **kwargs)

        # modifier la matrice d'adjacence ici
        self.adjacency_matrix = {0: [1,2], 1: [2], 2: [1,3,5], 3: [2], 4: [6], 5: [2,6], 6: [5,4]}
        
        # Initialisation : On clone le state_dict initial pour chaque client
        initial_state = model.state_dict()
        self.client_states = {
            client.index: copy.deepcopy(model.state_dict()) # <--- CORRECT : On extrait les poids
            for client in clients
        }

    def broadcast_model(self, eligible):
        """
        Surcharge de la mÃ©thode de server.py.
        Au lieu de broadcaster le self.model global, on envoie Ã  chaque client
        sa version spÃ©cifique stockÃ©e dans self.client_states.
        """
        for client in eligible:
            # 1. Charger l'Ã©tat spÃ©cifique du client dans le conteneur du serveur
            my_state = self.client_states[client.index]
            self.model.load_state_dict(my_state)
            
            # 2. CrÃ©er une copie pour l'envoi (important pour Ã©viter les conflits mÃ©moire en simulation)
            # On envoie un objet modÃ¨le car client.py attend un objet ayant .state_dict()
            model_to_send = copy.deepcopy(self.model)
            
            # 3. Envoyer en unicast via le channel
            # self.channel.send(
            #     Message(model_to_send, "model", dst=client.index, src="server"), 
            #     dest=str(client.index) # Le channel attend souvent un str ou l'ID direct selon l'implÃ©mentation
            # )
            self.channel.broadcast(
                Message(model_to_send, "model", "server"),
                [client.index]
            )

    def aggregate(self, eligible, client_models_gen):
        """
        Logique de Gossip / Consensus.
        1. On rÃ©cupÃ¨re les mises Ã  jour des clients qui ont travaillÃ©.
        2. Pour chaque client, on agrÃ¨ge son nouveau modÃ¨le avec ceux de ses voisins.
        """

        # conversion du gÃ©nÃ©rateur en liste si nÃ©cessaire
        client_models = list(client_models_gen)

        # 1. Mise Ã  jour des Ã©tats LOCAUX
        # ATTENTION : server.fit() envoie des OBJETS modÃ¨les, il faut extraire le state_dict
        for client, model_obj in zip(eligible, client_models):
            # C'est ici qu'on Ã©vite l'erreur pour le prochain round
            self.client_states[client.index] = copy.deepcopy(model_obj.state_dict())

        # 2. Logique de mÃ©lange (Gossip)
        next_round_states = {}
        
        for client in self.clients:
            cid = client.index
            neighbors = self.adjacency_matrix.get(cid, [])
            
            # On rÃ©cupÃ¨re les dictionnaires (state_dicts) stockÃ©s
            states_to_avg = [self.client_states[cid]]
            for nid in neighbors:
                if nid in self.client_states:
                    states_to_avg.append(self.client_states[nid])
            
            # On fait la moyenne des dictionnaires
            next_round_states[cid] = self._average_state_dicts(states_to_avg)

        self.client_states = next_round_states
        
        # Optionnel : On met Ã  jour self.model avec la moyenne globale juste pour l'Ã©valuation "Server-side"
        # si vous voulez garder une trace de la performance globale du rÃ©seau.
        all_states = list(self.client_states.values())
        self.model.load_state_dict(self._average_state_dicts(all_states))

    def _average_state_dicts(self, state_dicts):
        """Fonction utilitaire pour moyenner une liste de state_dicts."""
        if not state_dicts:
            return None
        
        avg_state = copy.deepcopy(state_dicts[0])
        n = len(state_dicts)
        
        for key in avg_state.keys():
            # On gÃ¨re les tenseurs float, on ignore les LongTensor (ex: num_batches_tracked) souvent non moyennables
            if avg_state[key].is_floating_point():
                avg_state[key] = sum(d[key] for d in state_dicts) / n
                
        return avg_state
    
    def _compute_evaluation(self, round: int, eligible: Sequence[Client]) -> None:
        """
        Surcharge pour afficher les performances individuelles.
        """
        # 1. On garde le comportement standard (Global eval) si dÃ©sirÃ©
        super()._compute_evaluation(round, eligible)

        # 2. Notre affichage personnalisÃ©
        console = Console()
        table = Table(title=f"ðŸ“Š Performances P2P - Round {round + 1}")

        table.add_column("Client ID", justify="center", style="cyan")
        table.add_column("Accuracy", justify="right", style="green")
        table.add_column("Loss", justify="right", style="red")

        # On Ã©value chaque client participant
        evaluator = FlukeENV().get_evaluator()
        
        # Note: server.py utilise eligible, mais pour le P2P on peut vouloir tout le monde
        # Si vous voulez Ã©valuer tout le monde, remplacez 'eligible' par 'self.clients'
        # Attention : Ã©valuer tout le monde est plus long.
        for client in eligible:
            # client.evaluate utilise le modÃ¨le local du client
            metrics = client.evaluate(evaluator, self.test_set)
            
            # Protection si l'Ã©valuation Ã©choue ou retourne vide
            acc = metrics.get('accuracy', 0.0)
            loss = metrics.get('loss', 0.0) # Si le loss est calculÃ© par l'Ã©valuateur

            table.add_row(
                str(client.index), 
                f"{acc:.4f}", 
                f"{loss:.4f}" if loss else "N/A"
            )

        console.print(table)

class P2PClient(Client):

    # we override the fit method to implement our training "strategy"
    def fit(self, override_local_epochs: int = 0) -> float:
        # we can override the number of local epochs and call the parent class method
        new_local_epochs = np.random.randint(1, self.hyper_params.local_epochs + 1)
        return super().fit(new_local_epochs)
    
from fluke.algorithms import CentralizedFL

class P2P(CentralizedFL):

    def get_client_class(self) -> type[Client]:
        return P2PClient

    def get_server_class(self) -> type[Server]:
        return P2PServer


